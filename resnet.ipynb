{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f36a7e9-1513-4446-94d3-f0aec832544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47a4fad-6c43-4ac6-878c-c88b9a1c2885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"resnet_cladec.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/15B7zM6hqhHcThqoxCFrT-U4_EYNC8RVS\n",
    "\"\"\"\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "import torchvision, torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import numpy as np, sklearn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from shutil import copyfile\n",
    "\n",
    "from torchvision.transforms.transforms import CenterCrop, Resize\n",
    "\n",
    "\n",
    "gds = lambda dataset, cfg: torch.utils.data.DataLoader(\n",
    "    TensorDataset(*[torch.from_numpy(x) for x in dataset]), batch_size=cfg[\"batchSize\"]\n",
    ")\n",
    "\n",
    "\n",
    "def getnorm(dname):\n",
    "    if dname == \"Ci10\":\n",
    "        return (\n",
    "            torch.from_numpy(\n",
    "                np.array((0.4914, 0.4822, 0.4465), np.float32).reshape(1, 3, 1, 1)\n",
    "            ).cuda(),\n",
    "            torch.from_numpy(\n",
    "                np.array((0.2023, 0.1994, 0.2010), np.float32).reshape(1, 3, 1, 1)\n",
    "            ).cuda(),\n",
    "        )\n",
    "    elif dname == \"Ci100\":\n",
    "        return (\n",
    "            torch.from_numpy(\n",
    "                np.array((0.5060725, 0.48667726, 0.4421305), np.float32).reshape(\n",
    "                    1, 3, 1, 1\n",
    "                )\n",
    "            ).cuda(),\n",
    "            torch.from_numpy(\n",
    "                np.array((0.2675421, 0.25593522, 0.27593908), np.float32).reshape(\n",
    "                    1, 3, 1, 1\n",
    "                )\n",
    "            ).cuda(),\n",
    "        )\n",
    "    elif dname == \"Fash\":\n",
    "        return (\n",
    "            torch.from_numpy(np.array((0.281), np.float32).reshape(1, 1, 1, 1)).cuda(),\n",
    "            torch.from_numpy(np.array((0.352), np.float32).reshape(1, 1, 1, 1)).cuda(),\n",
    "        )\n",
    "    elif dname == \"MNIST\":\n",
    "        return (\n",
    "            torch.from_numpy(np.array((0.1307), np.float32).reshape(1, 1, 1, 1)).cuda(),\n",
    "            torch.from_numpy(np.array((0.3081), np.float32).reshape(1, 1, 1, 1)).cuda(),\n",
    "        )\n",
    "    elif dname == \"TinyImgNet\":\n",
    "        return (\n",
    "            torch.from_numpy(\n",
    "                np.array((0.4802, 0.4481, 0.3975), np.float32).reshape(3, 1, 1)\n",
    "            ),\n",
    "            torch.from_numpy(\n",
    "                np.array((0.2302, 0.2265, 0.2262), np.float32).reshape(3, 1, 1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "def getFullDS(cfg, reconstr=False):\n",
    "    dname = cfg[\"ds\"][0]\n",
    "    trans = transforms.Compose([transforms.ToTensor()])\n",
    "    refu = lambda x: F.interpolate(x.unsqueeze(0), size=64).squeeze(0)\n",
    "    if dname == \"Ci10\":\n",
    "        cdat = (\n",
    "            torchvision.datasets.CIFAR10\n",
    "        )  # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]) #transform = transforms.Compose([transforms.ToTensor(), norm])\n",
    "        cfg[\"imCh\"] = 3\n",
    "    elif dname == \"Ci100\":\n",
    "        cdat = (\n",
    "            torchvision.datasets.CIFAR100\n",
    "        )  # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        cfg[\"imCh\"] = 3\n",
    "    elif dname == \"Fash\":\n",
    "        cdat = torchvision.datasets.FashionMNIST\n",
    "        # img = img - np.array([0.281])            img = img / np.array([0.352])\n",
    "        trans = transforms.Compose([transforms.ToTensor(), refu])\n",
    "        cfg[\"imCh\"] = 1\n",
    "    elif dname == \"MNIST\":\n",
    "        cdat = torchvision.datasets.MNIST\n",
    "        # trans = transforms.Compose([transforms.ToTensor(), refu, transforms.Normalize(0.1307,0.3081)])\n",
    "        trans = transforms.Compose([transforms.ToTensor(), refu])\n",
    "        cfg[\"imCh\"] = 1\n",
    "    elif dname == \"TinyImgNet\":\n",
    "        cdat = tinyImgNet\n",
    "        norm = getnorm(dname)\n",
    "        # gamma_corr = lambda img : transforms.functional.adjust_gamma(img, gamma=, float=)\n",
    "        # resize_tr = random.choice([transforms.RandomResizedCrop(56), transforms.CenterCrop(56)])\n",
    "        # aug_tr = random.choice([transforms.RandomHorizontalFlip(), transforms.RandomAffine(30, translate=10, scale = [0.8])])\n",
    "        # data_augs = [transforms.RandomResizedCrop(32), transforms.RandomCrop(32), transforms.RandomHorizontalFlip(), transforms.RandomRotation(45)]\n",
    "        train_trans = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=norm[0], std=norm[1]),\n",
    "                transforms.RandomResizedCrop(64),\n",
    "                # transforms.CenterCrop(56),\n",
    "                # transforms.Resize(32),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "            ]\n",
    "        )\n",
    "        val_trans = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.CenterCrop(56),\n",
    "                transforms.Normalize(mean=norm[0], std=norm[1]),\n",
    "                # transforms.Resize(32)\n",
    "            ]\n",
    "        )\n",
    "        cfg[\"imCh\"] = 3\n",
    "\n",
    "    ntrain, down = cfg[\"ntrain\"], True\n",
    "    if dname == \"TinyImgNet\":\n",
    "        down = False\n",
    "        if reconstr == True:\n",
    "            trainset = cdat(\n",
    "                root=\"data/\",\n",
    "                train=True,\n",
    "                download=down,\n",
    "                transform=transforms.Compose([transforms.ToTensor()]),\n",
    "            )\n",
    "            valset = cdat(\n",
    "                root=\"data/\",\n",
    "                train=False,\n",
    "                download=down,\n",
    "                transform=transforms.Compose([transforms.ToTensor()]),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            trainset = cdat(\n",
    "                root=\"data/\", train=True, download=down, transform=train_trans\n",
    "            )\n",
    "            valset = cdat(root=\"data/\", train=False, download=down, transform=val_trans)\n",
    "        train_loader = DataLoader(\n",
    "            trainset, batch_size=cfg[\"batchSize\"], shuffle=True, num_workers=4\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            valset, batch_size=cfg[\"batchSize\"], shuffle=False, num_workers=4\n",
    "        )\n",
    "        return train_loader, val_loader, None, trainset, valset\n",
    "\n",
    "    def loadStore(isTrain, ndat):\n",
    "        nonlocal cdat\n",
    "        trainset = cdat(root=\"data/\", train=isTrain, download=down, transform=trans)\n",
    "        train_dataset = torch.utils.data.DataLoader(\n",
    "            trainset, batch_size=ndat, num_workers=4\n",
    "        )  # cfg[\"batchSize\"]\n",
    "        ds = next(iter(train_dataset))\n",
    "        X, Y = ds[0].clone().numpy(), ds[1].clone().numpy()\n",
    "        # normA = lambda bx: (bx - np.min(bx)) / (np.max(bx) - np.min(bx) + 1e-10)  # \"Normalizing - necessary if no BN\"\n",
    "        # X,Y = normA(X), normA(Y)\n",
    "        ds = [X, Y]\n",
    "        print(\n",
    "            \"Data stats\",\n",
    "            cdat,\n",
    "            X.shape,\n",
    "            np.mean(X, axis=(0, 2, 3)),\n",
    "            np.std(X, axis=(0, 2, 3)),\n",
    "            np.max(X),\n",
    "            np.min(X),\n",
    "            \" Data should be normalized\",\n",
    "        )\n",
    "        ds = sklearn.utils.shuffle(*ds)\n",
    "        return ds[0].astype(np.float16), ds[1].astype(np.int16)\n",
    "\n",
    "    trX, trY = loadStore(True, ntrain)\n",
    "    teX, teY = loadStore(False, ntrain // 2)\n",
    "\n",
    "    def cds(trX, trY, shuffle=True):\n",
    "        ds = TensorDataset(torch.from_numpy(trX), torch.from_numpy(trY))\n",
    "        return DataLoader(\n",
    "            ds, batch_size=cfg[\"batchSize\"], shuffle=shuffle, num_workers=4, pin_memory=True\n",
    "        )\n",
    "\n",
    "    return cds(trX, trY), cds(teX, teY, False), None\n",
    "\n",
    "\n",
    "def tinyImgNet(root: str, train: bool, download: bool, transform) -> Dataset:\n",
    "    filter_val = train and not download\n",
    "\n",
    "    if download:\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "        r = requests.get(\n",
    "            \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\", stream=True\n",
    "        )\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall(root)\n",
    "\n",
    "    main_dir_path = os.path.join(root, \"tiny-imagenet-200\")\n",
    "    train_path = os.path.join(main_dir_path, \"train\")\n",
    "    val_path = os.path.join(main_dir_path, \"val\")\n",
    "    if not (os.path.exists(train_path) and os.path.exists(val_path)):\n",
    "        raise ValueError(\"Train and Val paths don't exist\")\n",
    "\n",
    "    val_formatted = os.path.join(main_dir_path, \"val_formatted\")\n",
    "    if not filter_val and not os.path.exists(val_formatted):\n",
    "        with open(os.path.join(val_path, \"val_annotations.txt\"), \"r\") as f:\n",
    "            img_class_map = f.readlines()\n",
    "        for img_class in img_class_map:\n",
    "            img_name, class_name = img_class.split(\"\\t\")[0], img_class.split(\"\\t\")[1]\n",
    "            img_path = os.path.join(\"images\", img_name)\n",
    "            class_dir = os.path.join(val_formatted, class_name)\n",
    "            os.makedirs(os.path.join(class_dir, \"images\"), exist_ok=True)\n",
    "            copyfile(\n",
    "                os.path.join(val_path, img_path), os.path.join(class_dir, img_path)\n",
    "            )\n",
    "    if train:\n",
    "        return ImageFolder(train_path, transform)\n",
    "    else:\n",
    "        return ImageFolder(val_formatted, transform)\n",
    "\n",
    "\n",
    "\n",
    "def decay(opt,epoch,optimizerCl):\n",
    "    if opt[0] == \"S\" and (epoch + 1) % (opt[1] // 3+opt[1]//10+2 ) == 0:\n",
    "        for p in optimizerCl.param_groups: p['lr'] *= 0.1\n",
    "        #print(\"  D\", np.round(optimizerCl.param_groups[0]['lr'],5))\n",
    "\n",
    "def getAcc(net, dataset,  niter=10000,norm=None):\n",
    "    correct,total = 0,0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for cit,data in enumerate(dataset):\n",
    "            with tca.autocast():\n",
    "                dsx,dsy = data[0].cuda(),data[1].cuda()\n",
    "                if len(dsx.size()) == 5:\n",
    "                    dsx = dsx.squeeze(0)\n",
    "                    dsy = dsy.squeeze(0)\n",
    "                total += dsy.size(0)\n",
    "                outputs = net(dsx.float())\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += torch.eq(predicted, dsy).sum().item()\n",
    "                if cit>=niter: break\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "def getclassifier(cfg,train_dataset,val_dataset,norm=None):\n",
    "\n",
    "    netCl=ResNet10(n_classes = cfg[\"ds\"][1], n_output_planes = [64, 128, 256, 512], inch = cfg[\"imCh\"]).cuda()\n",
    "    if cfg[\"ds\"][0] == \"TinyImgNet\":\n",
    "        optimizerCl = optim.Adam(netCl.parameters(), lr=cfg[\"opt\"][2], weight_decay=cfg[\"opt\"][3])\n",
    "    else:\n",
    "        optimizerCl = optim.SGD(netCl.parameters(), lr=cfg[\"opt\"][2], momentum=0.9, weight_decay=cfg[\"opt\"][3])\n",
    "    #optimizerCl = optim.SGD(netCl.parameters(), lr=cfg[\"opt\"][2], momentum=0.9, weight_decay=cfg[\"opt\"][3])\n",
    "    closs,teaccs,trep,loss,clr = 0,[],cfg[\"opt\"][1],nn.CrossEntropyLoss(), cfg[\"opt\"][2]\n",
    "    print(\"Train Classifier to explain\")\n",
    "    scaler = tca.GradScaler()\n",
    "    teAccs,trAccs=[],[]\n",
    "    clAcc = lambda dataset: getAcc(netCl, dataset,  niter=1e10,norm=norm)\n",
    "    for epoch in tqdm(range(trep)):\n",
    "        netCl.train()\n",
    "        for i, data in enumerate(tqdm(train_dataset, position=0, leave=True)):\n",
    "          with tca.autocast():\n",
    "            optimizerCl.zero_grad()\n",
    "            dsx = data[0]\n",
    "            dsx,dsy = dsx.cuda(),data[1].cuda()\n",
    "            if len(dsx.size()) == 5:\n",
    "                dsx = dsx.squeeze(0)\n",
    "                dsy = dsy.squeeze(0)\n",
    "            output = netCl(dsx.float())\n",
    "            errD_real = loss(output, dsy.long())\n",
    "            scaler.scale(errD_real).backward()\n",
    "            scaler.step(optimizerCl)\n",
    "            scaler.update()\n",
    "            closs = 0.97 * closs + 0.03 * errD_real.item() if i > 20 else 0.8 * closs + 0.2 * errD_real.item()\n",
    "        decay(cfg[\"opt\"],epoch,optimizerCl)\n",
    "        netCl.eval()\n",
    "        teAccs.append(clAcc(val_dataset))\n",
    "        if (epoch % 4 == 0 and epoch<=13) or (epoch % 20==0 and epoch>13):\n",
    "            print(epoch, np.round(np.array([closs, teAccs[-1], clAcc(train_dataset)]), 5))\n",
    "    lcfg = {\"testAcc\": clAcc(val_dataset), \"trainAcc\": clAcc(train_dataset)}\n",
    "    netCl.eval()\n",
    "    return netCl, lcfg\n",
    "\n",
    "import numpy as np\n",
    "import torch.cuda.amp as tca\n",
    "import torch\n",
    "from torch import nn\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class ClaDecNet(nn.Module):\n",
    "    def __init__(self, cfg, inShape, nFea):\n",
    "        super(ClaDecNet, self).__init__()\n",
    "        self.channel_mult = int(64)\n",
    "        self.expLinLay = len(inShape) == 2  # linear layer...\n",
    "\n",
    "        dim = 64 if self.expLinLay else 64 // int(inShape[-1])  # dimension of input\n",
    "        self.input_dim = np.prod(inShape[1:])\n",
    "        self.inFea = inShape[-2] if not self.expLinLay else 1\n",
    "        print(dim)\n",
    "        nLay = int(np.round(np.log2(dim) - 2))\n",
    "        \n",
    "\n",
    "        # Use batchnorm or bias? LeakyRelu or Relu   -->  Does not make much of a difference\n",
    "        # bn,bias = lambda x:  nn.BatchNorm2d(x),False\n",
    "        # rel =lambda x:  nn.LeakyReLU(0.01)\n",
    "        bn, bias = lambda x: nn.Identity(), True\n",
    "        rel = lambda x: nn.ReLU()\n",
    "        print(nLay)\n",
    "        if (\n",
    "            self.inFea == 1\n",
    "        ):  # There is no spatial dimension (or it is one) -> use a dense layer as the first layer\n",
    "            self.useDense = True\n",
    "            self.fc_output_dim = max(\n",
    "                self.input_dim, self.channel_mult\n",
    "            )  # number of input features\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(self.input_dim, self.fc_output_dim), nn.ReLU(True)\n",
    "            )  # , nn.BatchNorm1d(self.fc_output_dim)\n",
    "        else:  # The spatial extend is larger one, use a conv layer, otherwise have too many parameters\n",
    "            self.fc_output_dim = inShape[1]  # number of input features\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Conv2d(inShape[1], inShape[1], 3, stride=1, padding=1, bias=bias),\n",
    "                nn.ReLU(True),\n",
    "            )  # , nn.BatchNorm1d(self.fc_output_dim)\n",
    "            self.useDense = False\n",
    "        self.deconv = [\n",
    "            nn.ConvTranspose2d(\n",
    "                self.fc_output_dim,\n",
    "                int(self.channel_mult * (2 ** nLay)),\n",
    "                4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            bn(int(self.channel_mult * (2 ** nLay))),\n",
    "            rel(None),\n",
    "        ]\n",
    "        for j in range(nLay, 0, -1):\n",
    "            print(j)\n",
    "            self.deconv += [\n",
    "                nn.ConvTranspose2d(\n",
    "                    int(self.channel_mult * (2 ** j)),\n",
    "                    int(self.channel_mult * (2 ** (j - 1))),\n",
    "                    4,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    bias=bias,\n",
    "                ),\n",
    "                bn(int(self.channel_mult * (2 ** (j - 1)))),\n",
    "                rel(None),\n",
    "            ]\n",
    "        self.deconv.append(\n",
    "            nn.ConvTranspose2d(\n",
    "                self.channel_mult * 1, nFea, 4, stride=2, padding=1, bias=True\n",
    "            )\n",
    "        )\n",
    "        self.deconv = nn.Sequential(*self.deconv)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.useDense:\n",
    "            x = x.view(-1, self.input_dim)\n",
    "            x = self.fc(x)\n",
    "            x = x.view(-1, self.fc_output_dim, self.inFea, self.inFea)\n",
    "        else:\n",
    "            x = self.fc(x)\n",
    "        x = self.deconv(x)\n",
    "        x = self.sig(\n",
    "            x\n",
    "        )  # This sometimes gives better visualization, but you need to take care to standardize inputs as well\n",
    "        return x\n",
    "\n",
    "\n",
    "def getClaDec(cfg, netCl, norm, train_dataset):\n",
    "    alpha = cfg[\"alpha\"]\n",
    "    closs, cclloss, crloss, teaccs, trep, clloss, clr = (\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        [],\n",
    "        cfg[\"opt\"][1],\n",
    "        nn.CrossEntropyLoss(),\n",
    "        cfg[\"opt\"][2],\n",
    "    )\n",
    "    print(\"Train CLaDec\")\n",
    "    scaler = tca.GradScaler()\n",
    "    d = next(iter(train_dataset))\n",
    "    netDec = ClaDecNet(cfg, d[2].squeeze(0).shape, cfg[\"imCh\"]).cuda()\n",
    "    netDec.train()\n",
    "    netCl.train()\n",
    "    optimizerCl = torch.optim.Adam(netDec.parameters(), lr=0.0003, weight_decay=1e-5)\n",
    "    aeloss = nn.MSELoss()\n",
    "    ulo = (\n",
    "        lambda closs, totloss, i: 0.97 * closs + 0.03 * totloss.item()\n",
    "        if epoch > 20\n",
    "        else 0.8 * closs + 0.2 * totloss.item()\n",
    "    )\n",
    "    for epoch in tqdm(range(trep)):\n",
    "        for i, data in enumerate(train_dataset):\n",
    "            with tca.autocast():\n",
    "                optimizerCl.zero_grad()\n",
    "                if cfg[\"ds\"][0] == \"TinyImgNet\":\n",
    "                    dsx, dsy, dsact = (\n",
    "                        data[0].squeeze(0).cuda(),\n",
    "                        data[1].squeeze(0).cuda(),\n",
    "                        data[2].squeeze(0).cuda(),\n",
    "                    )\n",
    "                else:\n",
    "                    dsx, dsy, dsact = data[0].cuda(), data[1].cuda(), data[2].cuda()\n",
    "                output = netDec(dsact.float())\n",
    "                recloss = aeloss(output, dsx)\n",
    "                if cfg[\"ds\"][0] == \"TinyImgNet\":\n",
    "                    norm = getnorm(\"TinyImgNet\")\n",
    "                    transform = transforms.Compose(\n",
    "                        [\n",
    "                            transforms.Normalize(mean=norm[0], std=norm[1]),\n",
    "                            transforms.RandomResizedCrop(64),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                        ]\n",
    "                    )\n",
    "                    claloss = clloss(netCl(transform(output)), dsy.long())\n",
    "                else:\n",
    "                    claloss = clloss(netCl(output), dsy.long())\n",
    "                totloss = (1 - alpha) * recloss + alpha * claloss\n",
    "                scaler.scale(totloss).backward()\n",
    "                scaler.step(optimizerCl)\n",
    "                scaler.update()\n",
    "                closs, cclloss, crloss = (\n",
    "                    ulo(closs, totloss, epoch),\n",
    "                    ulo(cclloss, claloss, epoch),\n",
    "                    ulo(crloss, recloss, epoch),\n",
    "                )\n",
    "\n",
    "        decay(cfg[\"opt\"], epoch, optimizerCl)\n",
    "        if (epoch % 2 == 0 and epoch <= 10) or (epoch % 10 == 0 and epoch > 10):\n",
    "            print(epoch, np.round(np.array([closs, crloss, cclloss]), 5))\n",
    "\n",
    "    lcfg = {\"ClaLo\": closs}\n",
    "    netDec.eval()\n",
    "    return netDec, lcfg\n",
    "\n",
    "\n",
    "def getActModel(cfg, classifier):\n",
    "    ind = cfg[\"layInd\"]\n",
    "    if cfg[\"ds\"][0] == \"TinyImgNet\":\n",
    "        if ind < -1:\n",
    "            ind = ind - 3\n",
    "    actModel = nn.Sequential(*list(classifier.children())[:ind])\n",
    "    actModel.eval()\n",
    "    return actModel\n",
    "\n",
    "\n",
    "class RefAE(nn.Module):\n",
    "    def __init__(self, cfg, inShape):\n",
    "        super(RefAE, self).__init__()\n",
    "        self.cladec = ClaDecNet(cfg, inShape, cfg[\"imCh\"])\n",
    "        self.cladec.train()\n",
    "        cla = ResNet10(n_classes = cfg[\"ds\"][1], n_output_planes = [64, 128, 256, 512], inch = cfg[\"imCh\"]).cuda()\n",
    "        actModel = getActModel(cfg, cla)\n",
    "        actModel.train()\n",
    "        self.seq = nn.Sequential(actModel, self.cladec)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "\n",
    "def getRefAE(cfg, train_dataset):\n",
    "    closs, teaccs, trep, clloss, clr = (\n",
    "        0,\n",
    "        [],\n",
    "        cfg[\"opt\"][1],\n",
    "        nn.CrossEntropyLoss(),\n",
    "        cfg[\"opt\"][2],\n",
    "    )\n",
    "    print(\"Train RefAE\")\n",
    "    scaler = tca.GradScaler()\n",
    "    d = next(iter(train_dataset))\n",
    "    netDec = RefAE(cfg, d[2].squeeze(0).shape).cuda()\n",
    "    print(netDec)\n",
    "    netDec.train()\n",
    "    optimizerCl = torch.optim.Adam(netDec.parameters(), lr=0.0003, weight_decay=1e-5)\n",
    "    aeloss = nn.MSELoss()\n",
    "    ulo = (\n",
    "        lambda closs, totloss, i: 0.97 * closs + 0.03 * totloss.item()\n",
    "        if epoch > 20\n",
    "        else 0.8 * closs + 0.2 * totloss.item()\n",
    "    )\n",
    "    for epoch in tqdm(range(trep)):\n",
    "        for i, data in enumerate(train_dataset):\n",
    "            with tca.autocast():\n",
    "                optimizerCl.zero_grad()\n",
    "                if cfg[\"ds\"][0] == \"TinyImgNet\":\n",
    "                    dsx = data[0].squeeze(0).cuda()\n",
    "                else:\n",
    "                    dsx = data[0].cuda()\n",
    "                output = netDec(dsx.float())\n",
    "                recloss = aeloss(output, dsx)\n",
    "                scaler.scale(recloss).backward()\n",
    "                scaler.step(optimizerCl)\n",
    "                scaler.update()\n",
    "                closs = ulo(closs, recloss, epoch)\n",
    "\n",
    "        decay(cfg[\"opt\"], epoch, optimizerCl)\n",
    "        if (epoch % 2 == 0 and epoch <= 10) or (epoch % 10 == 0 and epoch > 10):\n",
    "            print(epoch, np.round(np.array([closs]), 5))\n",
    "\n",
    "    lcfg = {\"RefAELo\": closs}\n",
    "    netDec.eval()\n",
    "    return netDec, lcfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574cc882-afab-41ac-a843-b9adb37fed7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.round(np.log2(1) - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae82a7fe-38c8-405f-a58e-898e61dd53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as tca\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, bias=False):\n",
    "    \n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,padding=1, bias=bias)\n",
    "\n",
    "def variable_init(m, neg_slope=0.0):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, neg_slope)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        if m.weight is not None:\n",
    "            m.weight.data.fill_(1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "            m.running_mean.zero_()\n",
    "            m.running_var.zero_()\n",
    "\n",
    "class PlusMinusOne(object):\n",
    "    \"\"\" Scales values that are between [0, 1] into [-1, 1]. \"\"\"\n",
    "  \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = 2.0 * x - 1.0\n",
    "        return x    \n",
    "\n",
    "def _down_sample(x):\n",
    "    return nn.functional.avg_pool2d(x, 2, 2)\n",
    "\n",
    "def _increase_planes(x, n_out_planes):\n",
    "    n_samples, n_planes, spatial_size = x.size()[:-1]\n",
    "    x_zeros = torch.zeros(\n",
    "    n_samples, n_out_planes - n_planes, spatial_size, spatial_size, \n",
    "    dtype=x.dtype, device=x.device)\n",
    "    return torch.cat([x, x_zeros], 1)\n",
    "\n",
    "def _downsample_and_increase_planes(x, n_out_planes):\n",
    "    x = _down_sample(x)\n",
    "    x = _increase_planes(x, n_out_planes)\n",
    "    return x\n",
    "\n",
    "def identity_func(n_in_planes, n_out_planes, stride):\n",
    "    identity = lambda x: x\n",
    "    if stride == 2 and n_in_planes != n_out_planes:\n",
    "        identity = lambda x: _downsample_and_increase_planes(x, n_out_planes)\n",
    "    elif stride == 2:\n",
    "        identity = _down_sample\n",
    "    elif n_in_planes != n_out_planes:\n",
    "        identity = lambda x: _increase_planes(x, n_out_planes)\n",
    "    return identity\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, n_in_planes, n_out_planes, stride=1):\n",
    "        super().__init__()\n",
    "        assert stride == 1 or stride == 2\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "          conv3x3(n_in_planes, n_out_planes, stride),\n",
    "          nn.BatchNorm2d(n_out_planes),\n",
    "          nn.ReLU(inplace=True),\n",
    "          conv3x3(n_out_planes, n_out_planes),\n",
    "          nn.BatchNorm2d(n_out_planes)\n",
    "        )\n",
    "\n",
    "        self.identity = identity_func(n_in_planes, n_out_planes, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        identity = self.identity(x)\n",
    "\n",
    "        out += identity\n",
    "        out = nn.functional.relu(out)\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, n_in_planes, n_out_planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(n_in_planes, n_out_planes, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(n_out_planes)\n",
    "\n",
    "        self.conv2 = conv3x3(n_out_planes, n_out_planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(n_out_planes)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(n_out_planes, n_out_planes * 4, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm2d(n_out_planes * 4)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.identity = identity_func(n_in_planes, n_out_planes * 4, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        identity = self.identity(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, \n",
    "                     n_blocks, \n",
    "                     n_output_planes, \n",
    "                     n_classes,\n",
    "                     inch):\n",
    "        super(ResNet, self).__init__()\n",
    "        assert len(n_blocks) == 4\n",
    "        assert len(n_output_planes) == 4\n",
    "\n",
    "        self.n_in_planes = n_output_planes[0]\n",
    "\n",
    "        self.layer0 = nn.Sequential(\n",
    "          conv3x3(inch, self.n_in_planes),\n",
    "          nn.BatchNorm2d(self.n_in_planes),\n",
    "          nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer1 = self._make_layer(block, n_blocks[0], n_output_planes[0])\n",
    "        self.layer2 = self._make_layer(block, n_blocks[1], n_output_planes[1], 2)\n",
    "        self.layer3 = self._make_layer(block, n_blocks[2], n_output_planes[2], 2)\n",
    "        self.layer4 = self._make_layer(block, n_blocks[3], n_output_planes[3], 2)\n",
    "        self.fc = nn.Linear(n_output_planes[3] * block.expansion, n_classes, False)\n",
    "\n",
    "        self.apply(variable_init)\n",
    "\n",
    "    def _make_layer(self, block, n_blocks, n_out_planes, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.n_in_planes, n_out_planes, stride))\n",
    "        self.n_in_planes = n_out_planes * block.expansion\n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(self.n_in_planes, n_out_planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        spatial_size = x.size(2)\n",
    "        x = nn.functional.avg_pool2d(x, spatial_size, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def ResNet10(**kwargs):\n",
    "    return ResNet(BasicBlock, [1,1,1,1], **kwargs)\n",
    "\n",
    "def ResNet18(**kwargs):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], **kwargs)\n",
    "\n",
    "def ResNet34(**kwargs):\n",
    "    return ResNet(BasicBlock, [3,4,6,3], **kwargs)\n",
    "\n",
    "def ResNet50(**kwargs):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a426a714-6675-4b52-9039-314bd8d28ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing config {'ds': ('MNIST', 10), 'batchSize': 128, 'opt': ('S', 60, 0.1, 0.0001), 'layInd': -1, 'alpha': 0.001, 'ntrain': 60000}\n",
      "Get dataset\n",
      "Data stats <class 'torchvision.datasets.mnist.MNIST'> (60000, 1, 64, 64) [0.1308931] [0.30838418] 1.0 0.0  Data should be normalized\n",
      "Data stats <class 'torchvision.datasets.mnist.MNIST'> (10000, 1, 64, 64) [0.13275763] [0.31077635] 1.0 0.0  Data should be normalized\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,TensorDataset\n",
    "import numpy as np,os\n",
    "import torch.cuda.amp as tca\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def showPics(pics, mtit=\"\", tits =None,nrows = 16,ncols=12,fname=\"expPics\"):\n",
    "    picPerFig = nrows * ncols\n",
    "    for i in range(max(1,pics.shape[0] // picPerFig)):\n",
    "        fig = plt.figure(figsize=(20,30))\n",
    "        wm = plt.get_current_fig_manager()\n",
    "        wm.resize(*wm.window.maxsize())  # wm.window.state('zoomed')\n",
    "        fig.suptitle(mtit, fontsize=8)\n",
    "        for j in range(picPerFig):\n",
    "            if i * picPerFig + j == pics.shape[0]: break\n",
    "            ax1 = plt.subplot(nrows, (picPerFig - 1) // nrows + 1, j + 1)\n",
    "            if not tits is None and i*picPerFig + j<len(tits):\n",
    "               tit=ax1.set_title(str(tits[i*picPerFig + j]), fontsize=16)\n",
    "               plt.setp(tit, color='black')\n",
    "            cpic=pics[i * picPerFig + j].squeeze()\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "            ax1.axis('off')\n",
    "            cpic = 1-(cpic-np.min(cpic))/(np.max(cpic)-np.min(cpic)+1e-10)\n",
    "            plt.imshow(cpic.astype(np.float32),cmap='Greys')\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.savefig(fname+str(i)+ \".png\")\n",
    "        plt.close()\n",
    "        if i * picPerFig + j >= pics.shape[0] - 1: break\n",
    "\n",
    "def getActs(ds,actModel,cfg):\n",
    "        acts=[]\n",
    "        X,y=[],[]\n",
    "        for i, data in enumerate(ds):\n",
    "            with tca.autocast():\n",
    "                dsx, dsy = data[0].cuda(), data[1].cuda()\n",
    "                X.append(data[0])\n",
    "                y.append(data[1])\n",
    "                #classifier(dsx)\n",
    "                acts.append(actModel(dsx).detach().cpu())\n",
    "        X=torch.cat(X,dim=0)\n",
    "        y=torch.cat(y, dim=0)\n",
    "        conacts=torch.cat(acts,dim=0)\n",
    "        dsact=TensorDataset(X,y,conacts)\n",
    "        return torch.utils.data.DataLoader(dsact, batch_size=cfg[\"batchSize\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "dummy=False\n",
    "#dummy = True\n",
    "#cfg={ 'ds': ('Fash', 10),  #Dataset either  ('Ci100', 100) or ('Ci10', 10)\n",
    "#      'batchSize': 128, 'opt': ('S', 1 if dummy else 64, 0.1, 0.0001), #optimizer settings\n",
    "#      'layInd':-1, #Layer to explain (from last layer back, ie. -1 is last (linear), -2 is last conv, -3 second last conv)\n",
    "#      'alpha': 0.001, #tradeoff parameter reconstruction vs. classification loss\n",
    "#      'ntrain': 500 if dummy else 60000}\n",
    "cfg={ 'ds': ('MNIST', 10),  #Dataset either  ('Ci100', 100) or ('Ci10', 10)\n",
    "    'batchSize': 128, 'opt': ('S', 1 if dummy else 60, 0.1, 0.0001), #optimizer settings\n",
    "    'layInd':-1, #Layer to explain (from last layer back, ie. -1 is last (linear), -2 is last conv, -3 second last conv)\n",
    "    'alpha': 0.001, #tradeoff parameter reconstruction vs. classification loss\n",
    "    'ntrain': 500 if dummy else 60000}\n",
    "print(\"Executing config\",cfg)\n",
    "cfg[\"num_classes\"]=cfg[\"ds\"][1]\n",
    "#Get Data\n",
    "print(\"Get dataset\")\n",
    "train_dataset, val_dataset,norm=getFullDS(cfg)\n",
    "\n",
    "model_path = \"trained_models/resnet/MNIST\"\n",
    "import os\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be1d1f5-da23-495b-a7ee-4a8902ee19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg[\"opt\"] = ('S', 1 if dummy else 20, 0.1, 0.0001)\n",
    "# classifier, lcfg = getclassifier(cfg,  train_dataset, val_dataset, norm=norm)\n",
    "# print(\"Classifier Accuracy\",lcfg)\n",
    "# torch.save(classifier.state_dict(), os.path.join(model_path, \"classifier.pt\"))\n",
    "\n",
    "classifier = ResNet10(n_classes = cfg[\"ds\"][1], n_output_planes = [64, 128, 256, 512], inch = cfg[\"imCh\"])\n",
    "classifier.load_state_dict(torch.load(os.path.join(model_path, \"classifier.pt\")))\n",
    "classifier.cuda()\n",
    "\n",
    "def getReconstrDS(acts_ds,refAE,cladecNet,cfg):\n",
    "    X_cladec,X_refae,y=[],[],[]\n",
    "    cladec_loss, refae_loss = 0, 0\n",
    "    for i, data in enumerate(acts_ds):\n",
    "        #if i > 2: break\n",
    "        with tca.autocast():\n",
    "            with torch.no_grad():\n",
    "                dsx, dsy,dsact = data[0].cuda(), data[1], data[2].cuda()\n",
    "                outCla = cladecNet(dsact).detach().cpu().float()\n",
    "                outAE = refAE(dsx).detach().cpu().float()\n",
    "                dsx = dsx.detach().squeeze().cpu().float()\n",
    "                cladec_loss += (outCla - dsx).pow(2).mean()\n",
    "                refae_loss += (outAE - dsx).pow(2).mean()\n",
    "                X_cladec.append(outCla)\n",
    "                X_refae.append(outAE)\n",
    "                y.append(dsy)\n",
    "    \n",
    "    \n",
    "    refae_loss = refae_loss/i\n",
    "    cladec_loss = cladec_loss/i\n",
    "    X_cladec = torch.cat(X_cladec, dim = 0)\n",
    "    X_refae = torch.cat(X_refae, dim = 0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    cladec_ds = TensorDataset(X_cladec, y)\n",
    "    refae_ds = TensorDataset(X_refae, y)\n",
    "    \n",
    "    cladec_loader = torch.utils.data.DataLoader(cladec_ds, batch_size=cfg[\"batchSize\"], shuffle=True, num_workers=4)\n",
    "    refae_loader = torch.utils.data.DataLoader(refae_ds, batch_size=cfg[\"batchSize\"], shuffle=True, num_workers=4)\n",
    "    return cladec_loader, refae_loader, cladec_loss, refae_loss        \n",
    "        #X=torch.cat(X,dim=0)\n",
    "        #y=torch.cat(y, dim=0)\n",
    "        #dsact=TensorDataset(X,y,conacts)\n",
    "        #return torch.utils.data.DataLoader(dsact, batch_size=cfg[\"batchSize\"], shuffle=True, num_workers=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaff0195-f6dc-484e-a2cb-5acd5b77d703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "actModel = getActModel(cfg, classifier)\n",
    "actModel.eval()\n",
    "trds=getActs(train_dataset, actModel,cfg)\n",
    "\n",
    "d = next(iter(trds))\n",
    "cfg[\"layInd\"] = -3\n",
    "refAE = RefAE(cfg, d[2].squeeze(0).shape).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e66f5-be80-4c7b-a90d-005e95cfbbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d73cfd2e-e1d8-435b-bf44-69d380f166e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 64, 64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a497d5e-205d-4176-a7de-a49b0c7a049e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22389604-e87e-4772-8fe4-24333f8afb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_ordered = [x for x in val_dataset]\n",
    "# torch.save(batch_ordered,os.path.join(model_path, \"original.pt\"))\n",
    "# clf_preds = []\n",
    "# for (x,y) in batch_ordered:\n",
    "#     with torch.no_grad():\n",
    "#         with tca.autocast():\n",
    "#             clf_preds.append(classifier(x.cuda()).argmax(dim=1).detach().cpu())\n",
    "# torch.save(clf_preds, os.path.join(model_path,\"clf_preds.pt\"))\n",
    "\n",
    "ae_train_loss_list = []\n",
    "ae_val_loss_list = []\n",
    "cladec_train_loss_list = []\n",
    "cladec_val_loss_list = []\n",
    "cladec_val_acc = []\n",
    "refae_val_acc = []\n",
    "\n",
    "for i in range(4, 6):\n",
    "    cfg[\"opt\"] = ('S', 1 if dummy else 60, 0.1, 0.0001)\n",
    "    refae_path = os.path.join(model_path, \"refAE_{}.pt\".format(str(i)))\n",
    "    cladec_path = os.path.join(model_path, \"cladecNet_{}.pt\".format(str(i)))\n",
    "    cfg[\"layInd\"] = -1*i\n",
    "    #get Activations\n",
    "    actModel = getActModel(cfg, classifier)\n",
    "    actModel.eval()\n",
    "    trds=getActs(train_dataset, actModel,cfg)\n",
    "\n",
    "    #get RefAE\n",
    "    refAE,rcfg =getRefAE(cfg,trds) #Does not use activations themselves, only needs shape\n",
    "    print(rcfg)\n",
    "    torch.save(refAE.state_dict(), refae_path)\n",
    "    # Train ClaDec\n",
    "    cladecNet,ccfg=  getClaDec(cfg,classifier,None,trds)\n",
    "    print(\"ClaDec Final loss\", ccfg)\n",
    "    torch.save(cladecNet.state_dict(), cladec_path)\n",
    "\n",
    "    # refAE.eval()\n",
    "    # cladecNet.eval()\n",
    "    # actModel.eval()\n",
    "    \n",
    "    # train_acts = getActs(train_dataset, actModel, cfg)\n",
    "    # val_acts = getActs(val_dataset, actModel, cfg)\n",
    "    \n",
    "    # cladec_train, refae_train, cladec_train_loss, refae_train_loss = getReconstrDS(train_acts, refAE, cladecNet, cfg)\n",
    "    # cladec_val, refae_val, cladec_val_loss, refae_val_loss = getReconstrDS(train_acts, refAE, cladecNet, cfg)\n",
    "    \n",
    "    # ae_train_loss_list.append(refae_train_loss)\n",
    "    # ae_val_loss_list.append(refae_val_loss)\n",
    "    # cladec_train_loss_list.append(cladec_train_loss)\n",
    "    # cladec_val_loss_list.append(cladec_val_loss)\n",
    "    \n",
    "\n",
    "    # cfg[\"opt\"] = ('S', 1 if dummy else 20, 0.1, 0.0001)\n",
    "    # clf_cladec, lcfg_cladec = getclassifier(cfg,  cladec_train, cladec_val, norm=norm)\n",
    "    # cladec_val_acc.append(lcfg_cladec[\"testAcc\"])\n",
    "    # torch.save(clf_cladec.state_dict(), os.path.join(model_path, \"clf_cladec_\" + str(i) + \".pt\"))\n",
    "    # clf_ae, lcfg_ae = getclassifier(cfg,  refae_train, refae_val, norm=norm)\n",
    "    # refae_val_acc.append(lcfg_ae[\"testAcc\"])\n",
    "    # torch.save(clf_ae.state_dict(), os.path.join(model_path, \"clf_ae_\" + str(i) + \".pt\"))\n",
    "    # torch.save({\"cladec_train_loss\" : cladec_train_loss_list, \"cladec_val_loss\": cladec_val_loss_list, \"cladec_val_acc\" : cladec_val_acc}, os.path.join(model_path,\"cladec_metrics_{}.pt\".format(str(i))))\n",
    "    # torch.save({\"ae_train_loss\" : ae_train_loss_list, \"ae_val_loss\": ae_val_loss_list, \"ae_val_acc\" : refae_val_acc}, os.path.join(model_path, \"ae_metrics_{}.pt\".format(str(i))))\n",
    "\n",
    "\n",
    "\n",
    "    # ae_reconstr = []\n",
    "    # cladec_reconstr = []\n",
    "    # with tca.autocast():\n",
    "    #     for (x,y) in (batch_ordered):\n",
    "    #         y_pred_ae = clf_ae(x.cuda()).argmax(dim=1).detach().cpu()\n",
    "    #         ae_reconstr.append((refAE(x.cuda()).detach().cpu(),y_pred_ae))\n",
    "    #         y_pred_cladec = clf_cladec(x.cuda()).argmax(dim=1).detach().cpu()\n",
    "    #         cladec_reconstr.append((cladecNet(actModel(x.cuda())).detach().cpu(),y_pred_cladec))\n",
    "    \n",
    "    # torch.save(ae_reconstr,os.path.join(model_path, \"ae_reconstr_\" + str(i)+ \".pt\"))\n",
    "    # torch.save(cladec_reconstr,os.path.join(model_path, \"cladec_reconstr_\" + str(i)+ \".pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93429b-b2a9-482c-98b4-349ffaa096d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
